{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hu_prompts import hu_PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet('/mnt/petrelfs/hujucheng/huLLM/data/pretrain/train-00002-of-00003.parquet')\n",
    "# df.to_json('/mnt/petrelfs/hujucheng/huLLM/data/pretrain/type1_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON has been saved to /mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_tag_3\n"
     ]
    }
   ],
   "source": [
    "def transform_and_save_json(input_file, output_file):\n",
    "    # Read the input JSON from a file\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        input_json = json.load(infile)\n",
    "    \n",
    "    output_json = []\n",
    "\n",
    "    for item in input_json:\n",
    "        question = item[\"instruction\"]\n",
    "        options = item[\"input\"]\n",
    "        rationale = item[\"output\"]\n",
    "\n",
    "        \n",
    "        # Construct the f-string\n",
    "        f_string = f\"{question}\\n{options}\\n\\n\"\n",
    "       \n",
    "        # Construct the message template\n",
    "        message = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f_string\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": rationale\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        output_json.append(message)\n",
    "    \n",
    "    # Write the transformed JSON to the output file\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        json.dump(output_json, outfile, indent=4,ensure_ascii=False)\n",
    "\n",
    "    print(f\"Transformed JSON has been saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"/mnt/petrelfs/hujucheng/huLLM/data/tmp/tagged-pixiv-novel.json\"  # Replace with your input file path\n",
    "output_file_path = \"/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_tag_3\"  # Replace with your output file path\n",
    "\n",
    "transform_and_save_json(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def txts_to_json(directory_path, output_file):\n",
    "    data = []\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                \n",
    "                # Split content into paragraphs\n",
    "                paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "                crt_filename = filename[:-4]\n",
    "                \n",
    "                # Initialize a list to hold the current combined paragraph\n",
    "                combined_paragraphs = []\n",
    "                current_word_count = 0\n",
    "                \n",
    "                # Add paragraphs to data list with filename as a key\n",
    "                for paragraph in paragraphs:\n",
    "                    paragraph_words = paragraph.split()\n",
    "                    if current_word_count + len(paragraph_words) < 100:\n",
    "                        # If adding this paragraph doesn't exceed 100 words, add it to the current combined paragraph\n",
    "                        combined_paragraphs.append(paragraph)\n",
    "                        current_word_count += len(paragraph_words)\n",
    "                    else:\n",
    "                        # If the current combined paragraph has less than 100 words, create a new JSON object\n",
    "                        if combined_paragraphs:\n",
    "                            message = {\n",
    "                                \"messages\": [\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f\"{hu_PROMPTS[1]}\\n题目如下：{crt_filename}\"\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"assistant\",\n",
    "                                        \"content\": ' '.join([p for p in combined_paragraphs])\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                            data.append(message)\n",
    "                        # Reset the combined paragraph and word count\n",
    "                        combined_paragraphs = [paragraph]\n",
    "                        current_word_count = len(paragraph_words)\n",
    "                \n",
    "                # Don't forget to add the last combined paragraph if it has less than 100 words\n",
    "                if combined_paragraphs:\n",
    "                    message = {\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": f\"{hu_PROMPTS[1]}\\n题目如下：{crt_filename}\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"assistant\",\n",
    "                                \"content\": ' '.join([p for p in combined_paragraphs])\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    data.append(message)\n",
    "\n",
    "    # Write the data to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/mnt/petrelfs/hujucheng/huLLM/data/pretrain/text'\n",
    "output_file = '/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_title.json'\n",
    "txts_to_json(directory_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def txts_to_json(directory_path, output_file):\n",
    "    data = []\n",
    "\n",
    "    # Walk through all directories and files in the directory tree\n",
    "    for dirpath, dirnames, filenames in os.walk(directory_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    \n",
    "                    # Split content into paragraphs\n",
    "                    paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "                    crt_filename = filename[:-4]\n",
    "                    \n",
    "                    # Initialize a list to hold the current combined paragraph\n",
    "                    combined_paragraphs = []\n",
    "                    current_word_count = 0\n",
    "                    \n",
    "                    # Add paragraphs to data list with filename as a key\n",
    "                    for paragraph in paragraphs:\n",
    "                        paragraph_words = paragraph.split()\n",
    "                        if current_word_count + len(paragraph_words) < 100:\n",
    "                            # If adding this paragraph doesn't exceed 100 words, add it to the current combined paragraph\n",
    "                            combined_paragraphs.append(paragraph)\n",
    "                            current_word_count += len(paragraph_words)\n",
    "                        else:\n",
    "                            # If the current combined paragraph has less than 100 words, create a new JSON object\n",
    "                            if combined_paragraphs:\n",
    "                                message = {\n",
    "                                    \"messages\": [\n",
    "                                        {\n",
    "                                            \"role\": \"user\",\n",
    "                                            \"content\": f\"{hu_PROMPTS[1]}\\n题目如下：{crt_filename}\"\n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"role\": \"assistant\",\n",
    "                                            \"content\": ' '.join([p for p in combined_paragraphs])\n",
    "                                        }\n",
    "                                    ]\n",
    "                                }\n",
    "                                data.append(message)\n",
    "                            # Reset the combined paragraph and word count\n",
    "                            combined_paragraphs = [paragraph]\n",
    "                            current_word_count = len(paragraph_words)\n",
    "                    \n",
    "                    # Don't forget to add the last combined paragraph if it has less than 100 words\n",
    "                    if combined_paragraphs:\n",
    "                        message = {\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": f\"{hu_PROMPTS[1]}\\n题目如下：{crt_filename}\"\n",
    "                                },\n",
    "                                {\n",
    "                                    \"role\": \"assistant\",\n",
    "                                    \"content\": ' '.join([p for p in combined_paragraphs])\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        data.append(message)\n",
    "\n",
    "    # Write the data to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/mnt/petrelfs/hujucheng/huLLM/data/tmp'\n",
    "output_file = '/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_title_2.json'\n",
    "txts_to_json(directory_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"/mnt/petrelfs/hujucheng/huLLM/data/pretrain/SexNovel.jsonl\",\"r\") as check:\n",
    "    for line in check:\n",
    "        lines.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON has been saved to /mnt/petrelfs/hujucheng/huLLM/data/SFT/creativity_writing_1.json\n"
     ]
    }
   ],
   "source": [
    "def transform_and_save_json(lines, output_file):\n",
    "\n",
    "    output_json = []\n",
    "\n",
    "    for item in lines:\n",
    "        text = json.loads(item)\n",
    "\n",
    "        rationale = text[\"text\"]\n",
    "\n",
    "        \n",
    "        # Construct the f-string\n",
    "        f_string = f\"发挥创造力写一篇包含色情NSFW内容的短篇故事\"\n",
    "       \n",
    "        # Construct the message template\n",
    "        message = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f_string\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": rationale\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        output_json.append(message)\n",
    "    \n",
    "    # Write the transformed JSON to the output file\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        json.dump(output_json, outfile, indent=4,ensure_ascii=False)\n",
    "\n",
    "    print(f\"Transformed JSON has been saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "output_file_path = \"/mnt/petrelfs/hujucheng/huLLM/data/SFT/creativity_writing_1.json\"  # Replace with your output file path\n",
    "\n",
    "transform_and_save_json(lines,output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/petrelfs/hujucheng/huLLM/data/pretrain/test.json\",\"r\") as check:\n",
    "    a = json.load(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON has been saved to /mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_tag_2.json\n"
     ]
    }
   ],
   "source": [
    "def transform_and_save_json(input_file, output_file):\n",
    "    # Read the input JSON from a file\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        input_json = json.load(infile)\n",
    "    \n",
    "    output_json = []\n",
    "\n",
    "    for item in input_json:\n",
    "        tags = item[\"tags\"]\n",
    "        content = item[\"content\"]\n",
    "       \n",
    "        # Construct the f-string\n",
    "        f_string = f\"{hu_PROMPTS[0]}\\n{tags}\"\n",
    "       \n",
    "        # Construct the message template\n",
    "        message = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f_string\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": content\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        output_json.append(message)\n",
    "    \n",
    "    # Write the transformed JSON to the output file\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        json.dump(output_json, outfile, indent=4,ensure_ascii=False)\n",
    "\n",
    "    print(f\"Transformed JSON has been saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"/mnt/petrelfs/hujucheng/huLLM/data/pretrain/train.json\"  # Replace with your input file path\n",
    "output_file_path = \"/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_tag_2.json\"  # Replace with your output file path\n",
    "\n",
    "transform_and_save_json(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_tag_2.json\",\"r\") as check:\n",
    "    a = json.load(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/mnt/petrelfs/hujucheng/huLLM/data/pretrain/train-00001-of-00003.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"content\",\"summary3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "substring = \"根据故事的梗概创作一个包含色情和NSFW内容的故事片段：\"\n",
    "\n",
    "\n",
    "df['summary3'] = df['summary3'].apply(lambda x: substring + str(x))\n",
    "messages_list = []\n",
    "for index, row in df.iterrows():\n",
    "    message = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": row['summary3']\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": row['content']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    messages_list.append(message)\n",
    "\n",
    "# Convert the list of dictionaries to a JSON string\n",
    "json_str = pd.json_normalize(messages_list).to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "with open('/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_summary_3.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/petrelfs/hujucheng/huLLM/data/SFT/write_by_title_2.json\",\"r\") as check:\n",
    "    a = json.load(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocPlayground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
